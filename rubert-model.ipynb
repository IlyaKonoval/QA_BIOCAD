{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11690685,"sourceType":"datasetVersion","datasetId":7337692}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets\n!pip install rouge_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:34:34.797775Z","iopub.execute_input":"2025-05-06T16:34:34.798090Z","iopub.status.idle":"2025-05-06T16:34:40.845762Z","shell.execute_reply.started":"2025-05-06T16:34:34.798068Z","shell.execute_reply":"2025-05-06T16:34:40.845013Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import torch\nimport pickle\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\nfrom sklearn.model_selection import train_test_split\nimport re\nfrom rouge_score import rouge_scorer\nimport random\nimport nltk \nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:34:40.847675Z","iopub.execute_input":"2025-05-06T16:34:40.848372Z","iopub.status.idle":"2025-05-06T16:34:40.853147Z","shell.execute_reply.started":"2025-05-06T16:34:40.848340Z","shell.execute_reply":"2025-05-06T16:34:40.852485Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"with open('/kaggle/input/dataset/qa_dataset_full.pkl', 'rb') as f:\n    data = pickle.load(f)\n    \n    passages_train = data['train']['passages']\n    questions_train = data['train']['questions']\n    answers_train = data['train']['answers']\n    \n    passages_val = data['val']['passages']\n    questions_val = data['val']['questions']\n    answers_val = data['val']['answers']\n    \n    passages_test = data['test']['passages']\n    questions_test = data['test']['questions']\n    answers_test = data['test']['answers']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:34:40.854072Z","iopub.execute_input":"2025-05-06T16:34:40.854312Z","iopub.status.idle":"2025-05-06T16:34:40.989699Z","shell.execute_reply.started":"2025-05-06T16:34:40.854291Z","shell.execute_reply":"2025-05-06T16:34:40.989150Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"def prepare_dataset(passages, questions, answers):\n    dataset_dict = []\n    \n    # Преобразуем данные в формат для трансформеров\n    for i in range(len(questions)):\n        try:\n            question_id = questions['question_id'].iloc[i]\n            passage_id = questions['passage_id'].iloc[i]\n            question_text = questions['question_text'].iloc[i]\n            \n            # Находим соответствующий текст отрывка\n            passage_row = passages[passages['passage_id'] == passage_id]\n            if len(passage_row) == 0:\n                continue\n                \n            passage_text = passage_row['passage_text'].iloc[0]\n            \n            # Находим ответ на этот вопрос\n            answer_row = answers[(answers['passage_id'] == passage_id) & \n                                (answers['question_id'] == question_id)]\n            \n            if len(answer_row) == 0:\n                continue\n            \n            answer_id = answer_row['answer_id'].iloc[0]\n\n            # Удаляем номера и скобки в начале текста, если они есть\n            clean_passage = re.sub(r'^\\(\\d+\\)\\s*', '', passage_text)\n            \n            # 1. Используем первые 50-70 символов как ответ\n            short_answer = clean_passage[:min(70, len(clean_passage))]\n            \n            # 2. Ищем первое предложение\n            sentence_match = re.search(r'[^.!?]+[.!?]', clean_passage)\n            first_sentence = sentence_match.group(0) if sentence_match else short_answer\n            \n            # Выбираем ответ из стратегий\n            answer_text = first_sentence.strip()\n            \n            start_idx = passage_text.find(answer_text)\n            if start_idx == -1:\n                start_idx = 0\n            \n            dataset_dict.append({\n                'id': f\"{passage_id}-{question_id}\",\n                'context': passage_text,\n                'question': question_text,\n                'answers': {\n                    'text': [answer_text],\n                    'answer_start': [start_idx]\n                }\n            })\n            \n        except Exception as e:\n            print(f\"Ошибка при обработке примера {i}: {e}\")\n            continue\n    \n    return Dataset.from_list(dataset_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:34:40.990572Z","iopub.execute_input":"2025-05-06T16:34:40.990801Z","iopub.status.idle":"2025-05-06T16:34:40.998200Z","shell.execute_reply.started":"2025-05-06T16:34:40.990776Z","shell.execute_reply":"2025-05-06T16:34:40.997599Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"train_dataset = prepare_dataset(passages_train, questions_train, answers_train)\nval_dataset = prepare_dataset(passages_val, questions_val, answers_val)\ntest_dataset = prepare_dataset(passages_test, questions_test, answers_test)\n\nprint(f\"Размер обучающего набора: {len(train_dataset)}\")\nprint(f\"Размер валидационного набора: {len(val_dataset)}\")\nprint(f\"Размер тестового набора: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:34:41.000049Z","iopub.execute_input":"2025-05-06T16:34:41.000822Z","iopub.status.idle":"2025-05-06T16:34:44.523769Z","shell.execute_reply.started":"2025-05-06T16:34:41.000794Z","shell.execute_reply":"2025-05-06T16:34:44.523064Z"}},"outputs":[{"name":"stdout","text":"Размер обучающего набора: 2897\nРазмер валидационного набора: 529\nРазмер тестового набора: 1813\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"model_name = \"DeepPavlov/rubert-base-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:34:44.524459Z","iopub.execute_input":"2025-05-06T16:34:44.524708Z","iopub.status.idle":"2025-05-06T16:34:46.157051Z","shell.execute_reply.started":"2025-05-06T16:34:44.524682Z","shell.execute_reply":"2025-05-06T16:34:46.156274Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"def prepare_train_features(examples):\n    tokenized_examples = tokenizer(\n        examples[\"question\"],\n        examples[\"context\"],\n        truncation=\"only_second\",\n        max_length=384,\n        stride=128,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    # Маппинг между фичами и оригинальными примерами\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n\n    tokenized_examples[\"start_positions\"] = []\n    tokenized_examples[\"end_positions\"] = []\n\n    for i, offsets in enumerate(offset_mapping):\n        sample_idx = sample_mapping[i]\n        \n        # Получаем ответ\n        answer = examples[\"answers\"][sample_idx]\n        answer_text = answer[\"text\"][0]\n        start_char = answer[\"answer_start\"][0]\n        end_char = start_char + len(answer_text)\n        \n        # Находим токены начала и конца ответа\n        token_start_index = 0\n        token_end_index = 0\n        \n        # Находим первый токен, содержащий начало ответа\n        for idx, (start, end) in enumerate(offsets):\n            if start <= start_char and end > start_char:\n                token_start_index = idx\n                break\n                \n        # Находим последний токен, содержащий конец ответа\n        for idx, (start, end) in enumerate(offsets):\n            if start < end_char and end >= end_char:\n                token_end_index = idx\n                break\n        \n        # Если ответ не найден в токенах, устанавливаем CLS как ответ\n        if token_start_index == 0 and token_end_index == 0:\n            tokenized_examples[\"start_positions\"].append(0)\n            tokenized_examples[\"end_positions\"].append(0)\n        else:\n            tokenized_examples[\"start_positions\"].append(token_start_index)\n            tokenized_examples[\"end_positions\"].append(token_end_index)\n\n    return tokenized_examples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:34:46.157932Z","iopub.execute_input":"2025-05-06T16:34:46.158251Z","iopub.status.idle":"2025-05-06T16:34:46.165529Z","shell.execute_reply.started":"2025-05-06T16:34:46.158226Z","shell.execute_reply":"2025-05-06T16:34:46.164813Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"#Токенизируем набор данных\n\ntokenized_train = train_dataset.map(\n    prepare_train_features,\n    batched=True,\n    remove_columns=train_dataset.column_names\n)\n\ntokenized_val = val_dataset.map(\n    prepare_train_features,\n    batched=True,\n    remove_columns=val_dataset.column_names\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:34:46.166397Z","iopub.execute_input":"2025-05-06T16:34:46.166823Z","iopub.status.idle":"2025-05-06T16:34:48.561504Z","shell.execute_reply.started":"2025-05-06T16:34:46.166801Z","shell.execute_reply":"2025-05-06T16:34:48.560753Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2897 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e993e8726e0042d6a440ebf949ec00b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/529 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5257bd66edb34212a73e3544be9b0d54"}},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred # labels здесь могут не использоваться\n    start_logits, end_logits = predictions\n\n    predicted_answers = []\n    reference_answers = []\n\n    num_eval_samples = len(tokenized_val)\n    eval_indices = range(num_eval_samples)\n    original_indices = [tokenized_val[i]['overflow_to_sample_mapping'] for i in eval_indices] \\\n                       if 'overflow_to_sample_mapping' in tokenized_val.features else eval_indices\n    unique_original_indices = sorted(list(set(original_indices)))\n    examples_map = {i: val_dataset[i] for i in unique_original_indices}\n\n\n    for i in eval_indices:\n        start_logits_i = start_logits[i]\n        end_logits_i = end_logits[i]\n\n        start_idx = np.argmax(start_logits_i)\n        end_idx = np.argmax(end_logits_i)\n\n        if end_idx < start_idx:\n             end_idx = start_idx \n        try:\n            input_ids = tokenized_val[i][\"input_ids\"]\n        except IndexError:\n            print(f\"Предупреждение: Индекс {i} вне диапазона для tokenized_val. Пропуск.\")\n            continue\n\n        # Конвертируем предсказанные индексы токенов в текстовый ответ\n        tokens = tokenizer.convert_ids_to_tokens(input_ids)\n        valid_start_idx = min(start_idx, len(tokens) - 1)\n        valid_end_idx = min(end_idx, len(tokens) - 1)\n\n        if valid_end_idx < valid_start_idx:\n             valid_end_idx = valid_start_idx\n\n        answer_tokens = tokens[valid_start_idx : valid_end_idx + 1]\n        answer = tokenizer.convert_tokens_to_string(answer_tokens)\n\n        # Очищаем от специальных токенов\n        answer = answer.replace(tokenizer.cls_token, \"\").replace(tokenizer.sep_token, \"\").strip()\n\n        try:\n            if 'overflow_to_sample_mapping' in tokenized_val.features:\n                 original_sample_idx = tokenized_val[i]['overflow_to_sample_mapping']\n            else:\n                 original_sample_idx = i\n\n            reference = examples_map[original_sample_idx][\"answers\"][\"text\"][0]\n        except Exception as e:\n            print(f\"Предупреждение: Не удалось получить эталонный ответ для примера {i}. Ошибка: {e}\")\n            reference = \"\"\n\n        predicted_answers.append(answer)\n        reference_answers.append(reference)\n\n    def calculate_f1(pred, ref):\n        pred_tokens = set(pred.lower().split())\n        ref_tokens = set(ref.lower().split())\n\n        if not pred_tokens or not ref_tokens:\n            return 0.0\n\n        common_tokens = pred_tokens.intersection(ref_tokens)\n\n        precision = len(common_tokens) / len(pred_tokens)\n        recall = len(common_tokens) / len(ref_tokens)\n\n        if precision + recall == 0:\n            return 0.0\n\n        f1 = 2 * precision * recall / (precision + recall)\n        return f1\n\n    f1_scores = [calculate_f1(pred, ref) for pred, ref in zip(predicted_answers, reference_answers)]\n    f1_score = np.mean(f1_scores) if f1_scores else 0.0 # Используем numpy.mean для единообразия\n\n    rouge_scores_collected = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n\n    decoded_preds_rouge = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in predicted_answers]\n    decoded_labels_rouge = [\"\\n\".join(nltk.sent_tokenize(ref.strip())) for ref in reference_answers]\n\n    for pred, ref in zip(decoded_preds_rouge, decoded_labels_rouge):\n         if not pred or not ref:\n              continue\n         try:\n            score = scorer.score(ref, pred)\n            rouge_scores_collected['rouge1'].append(score['rouge1'].fmeasure)\n            rouge_scores_collected['rouge2'].append(score['rouge2'].fmeasure)\n            rouge_scores_collected['rougeL'].append(score['rougeL'].fmeasure)\n         except Exception as e:\n            print(f\"Предупреждение: Ошибка при вычислении ROUGE для пары: '{ref}' vs '{pred}'. Ошибка: {e}\")\n            pass\n\n\n    # Вычисляем среднее значение F1 для каждого типа ROUGE\n    rouge1_avg = np.mean(rouge_scores_collected['rouge1']) if rouge_scores_collected['rouge1'] else 0.0\n    rouge2_avg = np.mean(rouge_scores_collected['rouge2']) if rouge_scores_collected['rouge2'] else 0.0\n    rougeL_avg = np.mean(rouge_scores_collected['rougeL']) if rouge_scores_collected['rougeL'] else 0.0\n\n    result = {\n        \"f1\": round(f1_score * 100, 4),\n        \"rouge1\": round(rouge1_avg * 100, 4),\n        \"rouge2\": round(rouge2_avg * 100, 4),\n        \"rougeL\": round(rougeL_avg * 100, 4)\n    }\n\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:34:48.562430Z","iopub.execute_input":"2025-05-06T16:34:48.562730Z","iopub.status.idle":"2025-05-06T16:34:48.575369Z","shell.execute_reply.started":"2025-05-06T16:34:48.562705Z","shell.execute_reply":"2025-05-06T16:34:48.574815Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    learning_rate=1e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=20,\n    weight_decay=0.01,\n    report_to=\"none\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:57:59.983233Z","iopub.execute_input":"2025-05-06T18:57:59.983485Z","iopub.status.idle":"2025-05-06T18:58:00.009122Z","shell.execute_reply.started":"2025-05-06T18:57:59.983467Z","shell.execute_reply":"2025-05-06T18:58:00.008580Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:58:01.290015Z","iopub.execute_input":"2025-05-06T18:58:01.290306Z","iopub.status.idle":"2025-05-06T19:49:32.079429Z","shell.execute_reply.started":"2025-05-06T18:58:01.290287Z","shell.execute_reply":"2025-05-06T19:49:32.078364Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3505159916.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4081' max='4080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4080/4080 51:29, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.002500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.001100</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.001100</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.001000</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3505159916.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2625\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msteps_skipped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msteps_in_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2627\u001b[0;31m                         self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2628\u001b[0m                             \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m                             \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3198\u001b[0m         \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3199\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_internal_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_strategy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSaveStrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSaveStrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_global_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3902\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3904\u001b[0m         \u001b[0;31m# Push to the Hub when `save_model` is called by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3981\u001b[0m         \u001b[0;31m# If we are executing this function, we are the process zero, so we don't check for that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3982\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3983\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3984\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saving model checkpoint to {output_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device: './results/checkpoint-4080'"],"ename":"OSError","evalue":"[Errno 28] No space left on device: './results/checkpoint-4080'","output_type":"error"}],"execution_count":50},{"cell_type":"code","source":"def evaluate_qa_model(test_dataset, model, tokenizer, num_samples=None, random_seed=42):\n    \"\"\"\n    Функция для оценки метрик QA модели.\n    \"\"\"\n    # Установка seed для воспроизводимости\n    random.seed(random_seed)\n    np.random.seed(random_seed)\n    torch.manual_seed(random_seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(random_seed)\n    \n    # Определение устройства\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Используется устройство: {device}\")\n    \n    # Переводим модель на нужное устройство\n    model = model.to(device)\n    \n    # Выбор примеров для оценки\n    total_examples = len(test_dataset)\n    if num_samples is None:\n        num_samples = total_examples\n    else:\n        num_samples = min(num_samples, total_examples)\n    \n    indices = random.sample(range(total_examples), num_samples) if num_samples < total_examples else list(range(total_examples))\n    \n    # Инициализация ROUGE оценщика\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    \n    # Подготовка хранилища для результатов\n    results = {\n        'indices': indices,\n        'questions': [],\n        'references': [],\n        'predictions': [],\n        'f1_scores': [],\n        'rouge1_scores': [],\n        'rouge2_scores': [],\n        'rougeL_scores': [],\n        'confidence_scores': []\n    }\n    \n    # Функция для вычисления F1-score на уровне токенов\n    def calculate_token_f1(pred, ref):\n        if not pred or not ref:\n            return 0.0\n        \n        # Просто разделяем по пробелам для получения токенов\n        pred_tokens = set(pred.lower().split())\n        ref_tokens = set(ref.lower().split())\n        \n        if not pred_tokens or not ref_tokens:\n            return 0.0\n        \n        common_tokens = pred_tokens.intersection(ref_tokens)\n        \n        precision = len(common_tokens) / len(pred_tokens) if len(pred_tokens) > 0 else 0.0\n        recall = len(common_tokens) / len(ref_tokens) if len(ref_tokens) > 0 else 0.0\n        \n        if precision + recall == 0:\n            return 0.0\n        \n        f1 = 2 * precision * recall / (precision + recall)\n        return f1\n    \n    # Обработка примеров\n    print(f\"Оценка модели на {num_samples} примерах...\")\n    \n    for idx in tqdm(indices, desc=\"Обработка примеров\"):\n        try:\n            example = test_dataset[idx]\n            question = example[\"question\"]\n            context = example[\"context\"]\n            \n            # Проверка наличия эталонного ответа\n            if \"answers\" in example and \"text\" in example[\"answers\"] and len(example[\"answers\"][\"text\"]) > 0:\n                reference = example[\"answers\"][\"text\"][0]\n            else:\n                print(f\"Пример {idx} не содержит эталонного ответа. Пропускаем.\")\n                continue\n            \n            # Получаем ответ модели\n            try:\n                # Токенизация вопроса и контекста\n                inputs = tokenizer(\n                    question,\n                    context,\n                    return_tensors=\"pt\",\n                    max_length=384,\n                    truncation=\"only_second\",\n                    padding=\"max_length\"\n                )\n                \n                # Переносим входные данные на устройство\n                inputs = {k: v.to(device) for k, v in inputs.items()}\n                \n                # Получаем предсказания модели\n                with torch.no_grad():\n                    outputs = model(**inputs)\n                \n                # Находим наиболее вероятные начало и конец ответа\n                answer_start = torch.argmax(outputs.start_logits)\n                answer_end = torch.argmax(outputs.end_logits)\n                \n                # Корректируем индексы\n                if answer_end < answer_start:\n                    answer_end = answer_start\n                \n                # Декодируем ответ\n                tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n                answer_tokens = tokens[answer_start:answer_end+1]\n                predicted_answer = tokenizer.convert_tokens_to_string(answer_tokens)\n                \n                # Очищаем от специальных токенов\n                for special_token in tokenizer.special_tokens_map.values():\n                    if isinstance(special_token, str):\n                        predicted_answer = predicted_answer.replace(special_token, \"\")\n                    elif isinstance(special_token, list):\n                        for token in special_token:\n                            predicted_answer = predicted_answer.replace(token, \"\")\n                \n                predicted_answer = predicted_answer.strip()\n                \n                # Вычисляем уверенность\n                start_probs = torch.softmax(outputs.start_logits, dim=1)\n                end_probs = torch.softmax(outputs.end_logits, dim=1)\n                confidence = start_probs[0, answer_start].item() * end_probs[0, answer_end].item()\n                \n                # Вычисляем F1-score\n                f1 = calculate_token_f1(predicted_answer, reference)\n                \n                # Вычисляем ROUGE метрики\n                rouge_scores = {\"rouge1\": 0, \"rouge2\": 0, \"rougeL\": 0}\n                if predicted_answer.strip() and reference.strip():\n                    try:\n                        score = scorer.score(reference, predicted_answer)\n                        rouge_scores = {\n                            \"rouge1\": score['rouge1'].fmeasure,\n                            \"rouge2\": score['rouge2'].fmeasure,\n                            \"rougeL\": score['rougeL'].fmeasure\n                        }\n                    except Exception as e:\n                        print(f\"Ошибка при вычислении ROUGE для примера {idx}: {e}\")\n                \n                # Сохраняем результаты\n                results['questions'].append(question)\n                results['references'].append(reference)\n                results['predictions'].append(predicted_answer)\n                results['f1_scores'].append(f1)\n                results['rouge1_scores'].append(rouge_scores[\"rouge1\"])\n                results['rouge2_scores'].append(rouge_scores[\"rouge2\"])\n                results['rougeL_scores'].append(rouge_scores[\"rougeL\"])\n                results['confidence_scores'].append(confidence)\n                \n            except Exception as e:\n                print(f\"Ошибка при обработке примера {idx}: {e}\")\n                \n        except Exception as e:\n            print(f\"Ошибка при получении примера {idx}: {e}\")\n    \n    # Вычисление агрегированных метрик\n    if results['f1_scores']:\n        avg_f1 = np.mean(results['f1_scores'])\n        avg_rouge1 = np.mean(results['rouge1_scores'])\n        avg_rouge2 = np.mean(results['rouge2_scores'])\n        avg_rougeL = np.mean(results['rougeL_scores'])\n        avg_confidence = np.mean(results['confidence_scores'])\n        \n        # Вывод результатов\n        print(\"\\nРезультаты оценки:\")\n        print(f\"Всего обработано примеров: {len(results['f1_scores'])}\")\n        print(f\"Средний F1-score: {avg_f1:.4f}\")\n        print(f\"Средний ROUGE-1: {avg_rouge1:.4f}\")\n        print(f\"Средний ROUGE-2: {avg_rouge2:.4f}\")\n        print(f\"Средний ROUGE-L: {avg_rougeL:.4f}\")\n        print(f\"Средняя уверенность модели: {avg_confidence:.4f}\")\n        \n        # Показываем лучшие и худшие примеры\n        sorted_indices = np.argsort(results['f1_scores'])\n        \n        print(\"\\nПримеры с наихудшим F1-score:\")\n        for i in range(min(3, len(sorted_indices))):\n            idx = sorted_indices[i]\n            print(f\"F1: {results['f1_scores'][idx]:.4f}\")\n            print(f\"Вопрос: {results['questions'][idx]}\")\n            print(f\"Эталон: {results['references'][idx]}\")\n            print(f\"Предсказание: {results['predictions'][idx]}\")\n            print()\n        \n        print(\"\\nПримеры с наилучшим F1-score:\")\n        for i in range(min(3, len(sorted_indices))):\n            idx = sorted_indices[-(i+1)]\n            print(f\"F1: {results['f1_scores'][idx]:.4f}\")\n            print(f\"Вопрос: {results['questions'][idx]}\")\n            print(f\"Эталон: {results['references'][idx]}\")\n            print(f\"Предсказание: {results['predictions'][idx]}\")\n            print()\n        \n        results['aggregated'] = {\n            'avg_f1': avg_f1,\n            'avg_rouge1': avg_rouge1,\n            'avg_rouge2': avg_rouge2,\n            'avg_rougeL': avg_rougeL,\n            'avg_confidence': avg_confidence,\n            'num_examples': len(results['f1_scores'])\n        }\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:49:43.422005Z","iopub.execute_input":"2025-05-06T19:49:43.422580Z","iopub.status.idle":"2025-05-06T19:49:43.444684Z","shell.execute_reply.started":"2025-05-06T19:49:43.422558Z","shell.execute_reply":"2025-05-06T19:49:43.444077Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"eval_results = evaluate_qa_model(\n    test_dataset=test_dataset,\n    model=model,\n    tokenizer=tokenizer,\n    num_samples=None\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:49:48.447818Z","iopub.execute_input":"2025-05-06T19:49:48.448489Z","iopub.status.idle":"2025-05-06T19:50:30.651731Z","shell.execute_reply.started":"2025-05-06T19:49:48.448468Z","shell.execute_reply":"2025-05-06T19:50:30.651075Z"}},"outputs":[{"name":"stdout","text":"Используется устройство: cuda\nОценка модели на 1813 примерах...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Обработка примеров:   0%|          | 0/1813 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeebd59329724d668bdebd00f163d1c0"}},"metadata":{}},{"name":"stdout","text":"\nРезультаты оценки:\nВсего обработано примеров: 1813\nСредний F1-score: 0.6956\nСредний ROUGE-1: 0.1772\nСредний ROUGE-2: 0.0766\nСредний ROUGE-L: 0.1772\nСредняя уверенность модели: 0.9915\n\nПримеры с наихудшим F1-score:\nF1: 0.0000\nВопрос: Почему приятелю Ромашова всё показалось совершенно другим?\nЭталон: Лёжа на спине, я незаметно уснул.\nПредсказание: Почему приятелю Ромашова всё показалось совершенно другим\n\nF1: 0.0000\nВопрос: Что именно заставило ежа ахнуть от удивления, вернувшись со сбора грибов?\nЭталон: До самого вечера собирал ёжик грибы.\nПредсказание: именно заставило ежа ахнуть от удивления, вернувшись\n\nF1: 0.0000\nВопрос: Какой мужской предмет заметила Любовь Владимировна в руке у своего спутника, когда взяла его под руку?\nЭталон: Так, наверно, они и дошли бы до тепла, если бы не этот проклятый ветер.\nПредсказание: Какой мужской предмет заметила Любовь Владимировна в руке у своего спутника, когда взяла его под руку\n\n\nПримеры с наилучшим F1-score:\nF1: 1.0000\nВопрос: Стал ли обжаловать решение суда Данис Зарипов?\nЭталон: Нападающего сборной России по хоккею Даниса Зарипова лишили водительских прав на 18 месяцев.\nПредсказание: Нападающего сборной России по хоккею Даниса Зарипова лишили водительских прав на 18 месяцев.\n\nF1: 1.0000\nВопрос: Ясен источник крутых, прикольных, крыш и?\nЭталон: Какое же зеркало жизни наш язык!\nПредсказание: Какое же зеркало жизни наш язык!\n\nF1: 1.0000\nВопрос: Кого позвали в Гарвард читать лекции?\nЭталон: Повествователь примеряет своему герою истории, как платья.\nПредсказание: Повествователь примеряет своему герою истории, как платья.\n\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"model_path = \"./rubert_qa_model\"\ntrainer.model.save_pretrained(model_path)\ntokenizer.save_pretrained(model_path)\n","metadata":{"trusted":true},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"('./rubert_qa_model/tokenizer_config.json',\n './rubert_qa_model/special_tokens_map.json',\n './rubert_qa_model/vocab.txt',\n './rubert_qa_model/added_tokens.json',\n './rubert_qa_model/tokenizer.json')"},"metadata":{}}],"execution_count":53}]}