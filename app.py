import streamlit as st
import torch
from transformers import AutoModelForQuestionAnswering, AutoTokenizer

st.set_page_config(
    page_title="QA —Å–∏—Å—Ç–µ–º–∞",
    page_icon="‚ùì",
    layout="wide"
)

MODEL_NAME = "konoval03/rubert_qa_model"


@st.cache_resource
def load_model_from_hub():
    try:
        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
        model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)

        return model, tokenizer, device
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ –∏–∑ Hugging Face Hub: {e}")
        st.stop()


def answer_question(question, context, model, tokenizer, device):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    if not context:
        context = question

    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    inputs = tokenizer(
        question,
        context,
        return_tensors="pt",
        max_length=384,
        truncation="only_second",
        padding="max_length"
    )

    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)

    # –ü–æ–∏—Å–∫ –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π –Ω–∞—á–∞–ª–∞ –∏ –∫–æ–Ω—Ü–∞ –æ—Ç–≤–µ—Ç–∞
    answer_start = torch.argmax(outputs.start_logits)
    answer_end = torch.argmax(outputs.end_logits)

    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ–∑–∏—Ü–∏–π
    if answer_end < answer_start:
        answer_end = answer_start

    # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
    tokens = tokenizer.convert_ids_to_tokens(inputs["input_ids"][0])
    answer_tokens = tokens[answer_start:answer_end + 1]
    answer = tokenizer.convert_tokens_to_string(answer_tokens)

    # –û—á–∏—Å—Ç–∫–∞ –æ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
    for special_token in tokenizer.special_tokens_map.values():
        if isinstance(special_token, str):
            answer = answer.replace(special_token, "")
        elif isinstance(special_token, list):
            for token in special_token:
                answer = answer.replace(token, "")

    answer = answer.strip()

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
    start_probs = torch.softmax(outputs.start_logits, dim=1)
    end_probs = torch.softmax(outputs.end_logits, dim=1)
    confidence = start_probs[0, answer_start].item() * end_probs[0, answer_end].item()

    return answer, confidence


# –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
try:
    st.sidebar.title("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏")
    st.sidebar.markdown(f"–ú–æ–¥–µ–ª—å: [{MODEL_NAME}](https://huggingface.co/{MODEL_NAME})")
    st.sidebar.markdown("–ó–∞–¥–∞—á–∞: –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã (Question Answering)")

    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å Hugging Face Hub..."):
        model, tokenizer, device = load_model_from_hub()

    st.title("ü§ñ –°–∏—Å—Ç–µ–º–∞ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ")
    st.write("""
    –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–æ–±–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—Ä—ã–≤–æ–∫ (passage) –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ç–≤–µ—Ç–∞.
    """)

    # –û—Å–Ω–æ–≤–Ω–æ–π —Ä–∞–∑–¥–µ–ª –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    with st.form("qa_form"):
        question = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:")

        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—Ä—ã–≤–æ–∫
        document = st.text_area("–¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—Ä—ã–≤–æ–∫ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):", height=200)

        # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–æ—Ä–º—ã
        submit_button = st.form_submit_button("–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
    if submit_button and question:
        with st.spinner("–ü–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–∞..."):
            answer, confidence = answer_question(question, document, model, tokenizer, device)

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        st.write("### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        st.success(f"**–û—Ç–≤–µ—Ç:** {answer}")
        st.info(f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏:** {confidence:.2%}")

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        st.progress(min(confidence, 1.0))

        # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ, –µ—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –±—ã–ª –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
        if not document:
            st.warning("–û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –±–µ–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—Ä—ã–≤–∫–∞. –ï–≥–æ —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞.")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
    with st.expander("–û –º–æ–¥–µ–ª–∏"):
        st.write("""
        –≠—Ç–∞ —Å–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–¥–∞—á–∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—É—é —Å Hugging Face Hub.
        –ú–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å.

        **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç—ã:**
        - –ï—Å–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—Ä—ã–≤–æ–∫, –º–æ–¥–µ–ª—å –∏—â–µ—Ç –æ—Ç–≤–µ—Ç –≤ –Ω—ë–º
        - –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—Ä—ã–≤–æ–∫ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω, –º–æ–¥–µ–ª—å –ø—ã—Ç–∞–µ—Ç—Å—è –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç –∏—Å—Ö–æ–¥—è –∏–∑ —Å–∞–º–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
        - –õ—É—á—à–µ –≤—Å–µ–≥–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        """)

except Exception as e:
    st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
    st.write("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—É—Ç–∏ –∫ –º–æ–¥–µ–ª–∏ –Ω–∞ Hugging Face Hub.")